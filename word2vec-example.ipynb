{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'txt/0426.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "all_txt_files =[]\n",
    "# get all file names for obits in txt folder\n",
    "for root, dirs, files in os.walk(\"txt\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            all_txt_files.append(os.path.join(root, file))\n",
    "n_files = len(all_txt_files)\n",
    "all_txt_files[365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of strings. Each string is an obit\n",
    "all_text = []\n",
    "for i in all_txt_files:\n",
    "    with open(i) as f:\n",
    "        txt = f.read()\n",
    "    all_text.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "# check number of CPUs\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# define a function to tokenize, lowercase all, remove punctuation, remove numbers etc.\n",
    "def text_cleanup(mystring):\n",
    "    x = ['SPACE', 'PUNCT', 'SYM', 'X', 'NUM']\n",
    "    doc = nlp(mystring.lower())\n",
    "    processed = [i for i in doc if i.pos_ not in x]\n",
    "    processed = [i.text for i in processed if i.is_stop != True]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will take a long time to execute ... \n",
    "all_docs = [text_cleanup(i) for i in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 17:29:56,518 : INFO : collecting all words and their counts\n",
      "2018-11-15 17:29:56,519 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-15 17:29:56,597 : INFO : collected 35901 word types from a corpus of 454105 raw words and 366 sentences\n",
      "2018-11-15 17:29:56,597 : INFO : Loading a fresh vocabulary\n",
      "2018-11-15 17:29:56,642 : INFO : min_count=2 retains 21801 unique words (60% of original 35901, drops 14100)\n",
      "2018-11-15 17:29:56,643 : INFO : min_count=2 leaves 440005 word corpus (96% of original 454105, drops 14100)\n",
      "2018-11-15 17:29:56,725 : INFO : deleting the raw counts dictionary of 35901 items\n",
      "2018-11-15 17:29:56,727 : INFO : sample=0.001 downsamples 12 most-common words\n",
      "2018-11-15 17:29:56,727 : INFO : downsampling leaves estimated 426319 word corpus (96.9% of prior 440005)\n",
      "2018-11-15 17:29:56,776 : INFO : estimated required memory for 21801 words and 500 dimensions: 98104500 bytes\n",
      "2018-11-15 17:29:56,777 : INFO : resetting layer weights\n",
      "2018-11-15 17:29:57,316 : INFO : training model with 8 workers on 21801 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2018-11-15 17:29:57,761 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:57,763 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:57,791 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:57,792 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:57,794 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:57,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:57,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:57,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:57,825 : INFO : EPOCH - 1 : training on 454105 raw words (418878 effective words) took 0.5s, 828742 effective words/s\n",
      "2018-11-15 17:29:58,259 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:58,262 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:58,267 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:58,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:58,295 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:58,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:58,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:58,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:58,315 : INFO : EPOCH - 2 : training on 454105 raw words (418720 effective words) took 0.5s, 860326 effective words/s\n",
      "2018-11-15 17:29:58,752 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:58,755 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:58,763 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:58,777 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:58,781 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:58,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:58,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:58,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:58,803 : INFO : EPOCH - 3 : training on 454105 raw words (418827 effective words) took 0.5s, 864584 effective words/s\n",
      "2018-11-15 17:29:59,252 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:59,253 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:59,263 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:59,276 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:59,276 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:59,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:59,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:59,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:59,301 : INFO : EPOCH - 4 : training on 454105 raw words (418830 effective words) took 0.5s, 849867 effective words/s\n",
      "2018-11-15 17:29:59,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:59,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:59,753 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:59,763 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:59,773 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:59,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:59,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:59,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:59,793 : INFO : EPOCH - 5 : training on 454105 raw words (418906 effective words) took 0.5s, 857598 effective words/s\n",
      "2018-11-15 17:29:59,794 : INFO : training on a 2270525 raw words (2094161 effective words) took 2.5s, 845243 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(all_docs, size=500, window=6, min_count=2, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('girl', 0.9990344047546387),\n",
       " ('write', 0.998995840549469),\n",
       " ('unrequited', 0.9988707304000854),\n",
       " ('friends', 0.9986531138420105),\n",
       " (\"'re\", 0.9984126091003418),\n",
       " ('read', 0.9983095526695251),\n",
       " ('pickford', 0.9982596635818481),\n",
       " ('nightingale', 0.9982486367225647),\n",
       " ('recalled', 0.9981932044029236),\n",
       " ('live', 0.9981801509857178)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8615039758465234"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995969269476518"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('success', 'wealth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for y in model.wv.vocab.keys():\n",
    "    score = model.similarity('wealth', y)\n",
    "    pairs.append((y, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>wealth</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>fingers</td>\n",
       "      <td>0.999902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>aware</td>\n",
       "      <td>0.999880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>scenes</td>\n",
       "      <td>0.999845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>murder</td>\n",
       "      <td>0.999835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>riding</td>\n",
       "      <td>0.999828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>bands</td>\n",
       "      <td>0.999827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>admirers</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>cast</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14074</th>\n",
       "      <td>uncommon</td>\n",
       "      <td>0.999816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>sensation</td>\n",
       "      <td>0.999811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>image</td>\n",
       "      <td>0.999809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>count</td>\n",
       "      <td>0.999808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>hope</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>course</td>\n",
       "      <td>0.999797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>sentence</td>\n",
       "      <td>0.999793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>dazzling</td>\n",
       "      <td>0.999793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19756</th>\n",
       "      <td>detached</td>\n",
       "      <td>0.999791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>extraordinary</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>explored</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>comrades</td>\n",
       "      <td>0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>occasion</td>\n",
       "      <td>0.999771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>bird</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>personality</td>\n",
       "      <td>0.999764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>genius</td>\n",
       "      <td>0.999763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>affair</td>\n",
       "      <td>0.999763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>rolling</td>\n",
       "      <td>0.999761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>eddie</td>\n",
       "      <td>0.999759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>penny</td>\n",
       "      <td>0.999758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>height</td>\n",
       "      <td>0.999754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21665</th>\n",
       "      <td>secretions</td>\n",
       "      <td>-0.011725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21678</th>\n",
       "      <td>caresses</td>\n",
       "      <td>-0.015777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21537</th>\n",
       "      <td>dimbleby</td>\n",
       "      <td>-0.017796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21650</th>\n",
       "      <td>epithelial</td>\n",
       "      <td>-0.019211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21666</th>\n",
       "      <td>cheerless</td>\n",
       "      <td>-0.028827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21681</th>\n",
       "      <td>dawson</td>\n",
       "      <td>-0.029253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21659</th>\n",
       "      <td>shrady</td>\n",
       "      <td>-0.033307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>manassas</td>\n",
       "      <td>-0.036650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21670</th>\n",
       "      <td>drexel</td>\n",
       "      <td>-0.038650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21652</th>\n",
       "      <td>epithelia</td>\n",
       "      <td>-0.042457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21672</th>\n",
       "      <td>sha</td>\n",
       "      <td>-0.046624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>anterior</td>\n",
       "      <td>-0.048816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21658</th>\n",
       "      <td>anodynes</td>\n",
       "      <td>-0.059992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21661</th>\n",
       "      <td>ulcerative</td>\n",
       "      <td>-0.068279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21684</th>\n",
       "      <td>chagrined</td>\n",
       "      <td>-0.069246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21673</th>\n",
       "      <td>adjoined</td>\n",
       "      <td>-0.073276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>despondent</td>\n",
       "      <td>-0.092143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15603</th>\n",
       "      <td>ascap</td>\n",
       "      <td>-0.100090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21682</th>\n",
       "      <td>clemens</td>\n",
       "      <td>-0.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21792</th>\n",
       "      <td>cratty</td>\n",
       "      <td>-0.125499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>watrous</td>\n",
       "      <td>-0.185046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>bethesda</td>\n",
       "      <td>-0.284309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>hounds</td>\n",
       "      <td>-0.333091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19033</th>\n",
       "      <td>onslaughts</td>\n",
       "      <td>-0.358249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20454</th>\n",
       "      <td>dixieland</td>\n",
       "      <td>-0.377999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19021</th>\n",
       "      <td>calvary</td>\n",
       "      <td>-0.477657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>huey</td>\n",
       "      <td>-0.498717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20025</th>\n",
       "      <td>baehr</td>\n",
       "      <td>-0.538801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>videotape</td>\n",
       "      <td>-0.630336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16789</th>\n",
       "      <td>handbook</td>\n",
       "      <td>-0.883222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21801 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     score\n",
       "6872          wealth  1.000000\n",
       "605          fingers  0.999902\n",
       "2283           aware  0.999880\n",
       "663           scenes  0.999845\n",
       "925           murder  0.999835\n",
       "5875          riding  0.999828\n",
       "11578          bands  0.999827\n",
       "7833        admirers  0.999821\n",
       "1262            cast  0.999817\n",
       "14074       uncommon  0.999816\n",
       "8407       sensation  0.999811\n",
       "7465           image  0.999809\n",
       "53             count  0.999808\n",
       "705             hope  0.999799\n",
       "2174          course  0.999797\n",
       "1957        sentence  0.999793\n",
       "3037        dazzling  0.999793\n",
       "19756       detached  0.999791\n",
       "123    extraordinary  0.999783\n",
       "10069       explored  0.999783\n",
       "26          comrades  0.999781\n",
       "4249        occasion  0.999771\n",
       "5363            bird  0.999767\n",
       "555      personality  0.999764\n",
       "67            genius  0.999763\n",
       "424           affair  0.999763\n",
       "3484         rolling  0.999761\n",
       "11964          eddie  0.999759\n",
       "4457           penny  0.999758\n",
       "875           height  0.999754\n",
       "...              ...       ...\n",
       "21665     secretions -0.011725\n",
       "21678       caresses -0.015777\n",
       "21537       dimbleby -0.017796\n",
       "21650     epithelial -0.019211\n",
       "21666      cheerless -0.028827\n",
       "21681         dawson -0.029253\n",
       "21659         shrady -0.033307\n",
       "21697       manassas -0.036650\n",
       "21670         drexel -0.038650\n",
       "21652      epithelia -0.042457\n",
       "21672            sha -0.046624\n",
       "21656       anterior -0.048816\n",
       "21658       anodynes -0.059992\n",
       "21661     ulcerative -0.068279\n",
       "21684      chagrined -0.069246\n",
       "21673       adjoined -0.073276\n",
       "21668     despondent -0.092143\n",
       "15603          ascap -0.100090\n",
       "21682        clemens -0.116093\n",
       "21792         cratty -0.125499\n",
       "20927        watrous -0.185046\n",
       "14849       bethesda -0.284309\n",
       "11608         hounds -0.333091\n",
       "19033     onslaughts -0.358249\n",
       "20454      dixieland -0.377999\n",
       "19021        calvary -0.477657\n",
       "21412           huey -0.498717\n",
       "20025          baehr -0.538801\n",
       "17558      videotape -0.630336\n",
       "16789       handbook -0.883222\n",
       "\n",
       "[21801 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame.from_records(pairs, columns=[\"word\", \"score\"]).sort_values(by=\"score\", ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
